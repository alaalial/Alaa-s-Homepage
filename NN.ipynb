{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBtMv5J/V43LRauAPVbNgl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alaalial/Alaa-s-Homepage/blob/master/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eJEplhMEtBYb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VYMoaiojza_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8heVA6V8zrzU",
        "outputId": "7f05ebe4-a686-434f-c108-d39e809c3386"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a1f457-3b4e-4e8d-9254-3c3c22ef28a3",
        "id": "vWU1FvMWPjys"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gg9aye13uraI",
        "outputId": "c7b6e062-60fe-45fa-d9b3-23b567efa1a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1vGFSSpuw-_",
        "outputId": "cd736ab0-0fde-4dbf-9c27-afd199ddfcc4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 4185427239646018133\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14465892352\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 1747960849448187668\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa1vVuHTylDy",
        "outputId": "2a0531ad-1da4-4e93-a2a2-0772d7e242e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13302920 kB\n",
            "MemFree:         8985136 kB\n",
            "MemAvailable:   11700624 kB\n",
            "Buffers:          130048 kB\n",
            "Cached:          2516708 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          1627240 kB\n",
            "Inactive:        2315040 kB\n",
            "Active(anon):    1033472 kB\n",
            "Inactive(anon):    10700 kB\n",
            "Active(file):     593768 kB\n",
            "Inactive(file):  2304340 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               412 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       1295512 kB\n",
            "Mapped:           705516 kB\n",
            "Shmem:             11440 kB\n",
            "KReclaimable:     117708 kB\n",
            "Slab:             172788 kB\n",
            "SReclaimable:     117708 kB\n",
            "SUnreclaim:        55080 kB\n",
            "KernelStack:        5216 kB\n",
            "PageTables:        14424 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6651460 kB\n",
            "Committed_AS:    3928000 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       51368 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1448 kB\n",
            "AnonHugePages:      2048 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      219968 kB\n",
            "DirectMap2M:     6068224 kB\n",
            "DirectMap1G:     9437184 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n"
      ],
      "metadata": {
        "id": "8BDT0qRYyrcO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd "
      ],
      "metadata": {
        "id": "GXIMawNm9T2I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Artificial Neural Network\n",
        "\n",
        "\n",
        "# Part 1 - Data Preprocessing\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('/content/Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:13]\n",
        "y = dataset.iloc[:, 13]\n",
        "\n",
        "#Create dummy variables\n",
        "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
        "gender=pd.get_dummies(X['Gender'],drop_first=True)\n",
        "\n",
        "## Concatenate the Data Frames\n",
        "\n",
        "X=pd.concat([X,geography,gender],axis=1)\n",
        "\n",
        "## Drop Unnecessary columns\n",
        "X=X.drop(['Geography','Gender'],axis=1)\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Part 2 - Now let's make the ANN!\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "# Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer= 'he_uniform',activation='relu',input_dim = 11))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer= 'he_uniform',activation='relu'))\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1, kernel_initializer= 'glorot_uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)\n",
        "\n",
        "# list all data in history\n",
        "\n",
        "print(model_history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Part 3 - Making the predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate the Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_pred,y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wbYSZV1E9Un3",
        "outputId": "0e94b686-88aa-4bb2-a234-6066e71e8638"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 5s 8ms/step - loss: 0.6045 - accuracy: 0.7710 - val_loss: 0.5539 - val_accuracy: 0.7864\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.5277 - accuracy: 0.7949 - val_loss: 0.5015 - val_accuracy: 0.7982\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4871 - accuracy: 0.8041 - val_loss: 0.4746 - val_accuracy: 0.8031\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4652 - accuracy: 0.8108 - val_loss: 0.4599 - val_accuracy: 0.8035\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4521 - accuracy: 0.8123 - val_loss: 0.4520 - val_accuracy: 0.8054\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4437 - accuracy: 0.8155 - val_loss: 0.4474 - val_accuracy: 0.8069\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4379 - accuracy: 0.8175 - val_loss: 0.4444 - val_accuracy: 0.8092\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4337 - accuracy: 0.8188 - val_loss: 0.4423 - val_accuracy: 0.8103\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4305 - accuracy: 0.8196 - val_loss: 0.4412 - val_accuracy: 0.8095\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4281 - accuracy: 0.8205 - val_loss: 0.4399 - val_accuracy: 0.8084\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4265 - accuracy: 0.8205 - val_loss: 0.4389 - val_accuracy: 0.8088\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4247 - accuracy: 0.8203 - val_loss: 0.4381 - val_accuracy: 0.8092\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4233 - accuracy: 0.8229 - val_loss: 0.4371 - val_accuracy: 0.8084\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4217 - accuracy: 0.8216 - val_loss: 0.4365 - val_accuracy: 0.8099\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4203 - accuracy: 0.8229 - val_loss: 0.4359 - val_accuracy: 0.8107\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4191 - accuracy: 0.8248 - val_loss: 0.4353 - val_accuracy: 0.8095\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4177 - accuracy: 0.8248 - val_loss: 0.4348 - val_accuracy: 0.8114\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4168 - accuracy: 0.8248 - val_loss: 0.4340 - val_accuracy: 0.8099\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4155 - accuracy: 0.8248 - val_loss: 0.4334 - val_accuracy: 0.8114\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4143 - accuracy: 0.8270 - val_loss: 0.4327 - val_accuracy: 0.8080\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4132 - accuracy: 0.8261 - val_loss: 0.4318 - val_accuracy: 0.8111\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4122 - accuracy: 0.8263 - val_loss: 0.4308 - val_accuracy: 0.8111\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4108 - accuracy: 0.8255 - val_loss: 0.4299 - val_accuracy: 0.8111\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4093 - accuracy: 0.8270 - val_loss: 0.4288 - val_accuracy: 0.8118\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4078 - accuracy: 0.8272 - val_loss: 0.4275 - val_accuracy: 0.8133\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4061 - accuracy: 0.8276 - val_loss: 0.4257 - val_accuracy: 0.8114\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4043 - accuracy: 0.8289 - val_loss: 0.4238 - val_accuracy: 0.8137\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4023 - accuracy: 0.8304 - val_loss: 0.4220 - val_accuracy: 0.8160\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.4001 - accuracy: 0.8300 - val_loss: 0.4202 - val_accuracy: 0.8167\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3978 - accuracy: 0.8328 - val_loss: 0.4181 - val_accuracy: 0.8171\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3956 - accuracy: 0.8336 - val_loss: 0.4161 - val_accuracy: 0.8186\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3933 - accuracy: 0.8358 - val_loss: 0.4142 - val_accuracy: 0.8179\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3912 - accuracy: 0.8377 - val_loss: 0.4126 - val_accuracy: 0.8205\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3892 - accuracy: 0.8380 - val_loss: 0.4108 - val_accuracy: 0.8213\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3870 - accuracy: 0.8390 - val_loss: 0.4088 - val_accuracy: 0.8243\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3849 - accuracy: 0.8405 - val_loss: 0.4068 - val_accuracy: 0.8243\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 4s 8ms/step - loss: 0.3827 - accuracy: 0.8419 - val_loss: 0.4053 - val_accuracy: 0.8232\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3808 - accuracy: 0.8431 - val_loss: 0.4032 - val_accuracy: 0.8254\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3790 - accuracy: 0.8425 - val_loss: 0.4014 - val_accuracy: 0.8262\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3771 - accuracy: 0.8444 - val_loss: 0.3995 - val_accuracy: 0.8270\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3751 - accuracy: 0.8462 - val_loss: 0.3977 - val_accuracy: 0.8277\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3733 - accuracy: 0.8470 - val_loss: 0.3960 - val_accuracy: 0.8292\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3715 - accuracy: 0.8475 - val_loss: 0.3942 - val_accuracy: 0.8289\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3697 - accuracy: 0.8487 - val_loss: 0.3927 - val_accuracy: 0.8300\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3680 - accuracy: 0.8489 - val_loss: 0.3914 - val_accuracy: 0.8300\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3663 - accuracy: 0.8505 - val_loss: 0.3900 - val_accuracy: 0.8326\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3648 - accuracy: 0.8515 - val_loss: 0.3885 - val_accuracy: 0.8334\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3634 - accuracy: 0.8513 - val_loss: 0.3866 - val_accuracy: 0.8330\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3618 - accuracy: 0.8513 - val_loss: 0.3853 - val_accuracy: 0.8349\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3605 - accuracy: 0.8537 - val_loss: 0.3840 - val_accuracy: 0.8376\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3591 - accuracy: 0.8530 - val_loss: 0.3825 - val_accuracy: 0.8379\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3579 - accuracy: 0.8546 - val_loss: 0.3813 - val_accuracy: 0.8395\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3565 - accuracy: 0.8556 - val_loss: 0.3802 - val_accuracy: 0.8391\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3553 - accuracy: 0.8563 - val_loss: 0.3789 - val_accuracy: 0.8387\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3542 - accuracy: 0.8559 - val_loss: 0.3784 - val_accuracy: 0.8387\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3533 - accuracy: 0.8571 - val_loss: 0.3775 - val_accuracy: 0.8387\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3526 - accuracy: 0.8571 - val_loss: 0.3762 - val_accuracy: 0.8402\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3519 - accuracy: 0.8569 - val_loss: 0.3755 - val_accuracy: 0.8398\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3510 - accuracy: 0.8572 - val_loss: 0.3746 - val_accuracy: 0.8421\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3502 - accuracy: 0.8580 - val_loss: 0.3736 - val_accuracy: 0.8417\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3495 - accuracy: 0.8571 - val_loss: 0.3730 - val_accuracy: 0.8421\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3490 - accuracy: 0.8584 - val_loss: 0.3724 - val_accuracy: 0.8425\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3481 - accuracy: 0.8584 - val_loss: 0.3718 - val_accuracy: 0.8421\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3477 - accuracy: 0.8584 - val_loss: 0.3711 - val_accuracy: 0.8421\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3471 - accuracy: 0.8576 - val_loss: 0.3706 - val_accuracy: 0.8413\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3466 - accuracy: 0.8574 - val_loss: 0.3702 - val_accuracy: 0.8444\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3460 - accuracy: 0.8582 - val_loss: 0.3694 - val_accuracy: 0.8425\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3456 - accuracy: 0.8597 - val_loss: 0.3689 - val_accuracy: 0.8429\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3451 - accuracy: 0.8587 - val_loss: 0.3683 - val_accuracy: 0.8436\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3445 - accuracy: 0.8591 - val_loss: 0.3680 - val_accuracy: 0.8432\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3442 - accuracy: 0.8587 - val_loss: 0.3678 - val_accuracy: 0.8440\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3439 - accuracy: 0.8576 - val_loss: 0.3670 - val_accuracy: 0.8448\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3432 - accuracy: 0.8595 - val_loss: 0.3671 - val_accuracy: 0.8463\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3431 - accuracy: 0.8599 - val_loss: 0.3663 - val_accuracy: 0.8448\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3425 - accuracy: 0.8584 - val_loss: 0.3662 - val_accuracy: 0.8448\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3422 - accuracy: 0.8584 - val_loss: 0.3656 - val_accuracy: 0.8466\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3416 - accuracy: 0.8586 - val_loss: 0.3655 - val_accuracy: 0.8470\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3412 - accuracy: 0.8593 - val_loss: 0.3650 - val_accuracy: 0.8463\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3409 - accuracy: 0.8587 - val_loss: 0.3646 - val_accuracy: 0.8474\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3406 - accuracy: 0.8591 - val_loss: 0.3643 - val_accuracy: 0.8478\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3401 - accuracy: 0.8586 - val_loss: 0.3640 - val_accuracy: 0.8485\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3397 - accuracy: 0.8599 - val_loss: 0.3635 - val_accuracy: 0.8489\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3394 - accuracy: 0.8591 - val_loss: 0.3632 - val_accuracy: 0.8482\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3392 - accuracy: 0.8595 - val_loss: 0.3627 - val_accuracy: 0.8482\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3389 - accuracy: 0.8597 - val_loss: 0.3627 - val_accuracy: 0.8482\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3386 - accuracy: 0.8612 - val_loss: 0.3622 - val_accuracy: 0.8489\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3384 - accuracy: 0.8593 - val_loss: 0.3618 - val_accuracy: 0.8497\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3381 - accuracy: 0.8589 - val_loss: 0.3619 - val_accuracy: 0.8482\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3381 - accuracy: 0.8614 - val_loss: 0.3614 - val_accuracy: 0.8504\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3375 - accuracy: 0.8608 - val_loss: 0.3610 - val_accuracy: 0.8501\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3376 - accuracy: 0.8604 - val_loss: 0.3607 - val_accuracy: 0.8527\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3371 - accuracy: 0.8595 - val_loss: 0.3604 - val_accuracy: 0.8508\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3370 - accuracy: 0.8595 - val_loss: 0.3600 - val_accuracy: 0.8523\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3367 - accuracy: 0.8604 - val_loss: 0.3597 - val_accuracy: 0.8523\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3365 - accuracy: 0.8615 - val_loss: 0.3598 - val_accuracy: 0.8523\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3363 - accuracy: 0.8600 - val_loss: 0.3593 - val_accuracy: 0.8519\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3359 - accuracy: 0.8615 - val_loss: 0.3594 - val_accuracy: 0.8519\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3358 - accuracy: 0.8610 - val_loss: 0.3591 - val_accuracy: 0.8535\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3355 - accuracy: 0.8606 - val_loss: 0.3589 - val_accuracy: 0.8538\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3352 - accuracy: 0.8619 - val_loss: 0.3588 - val_accuracy: 0.8535\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-afd3475c6377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}